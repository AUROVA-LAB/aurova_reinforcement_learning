# Reference: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml#L32
seed: 42

n_timesteps: !!float 3e8      # Total timesteps in which the agent will learn
policy: 'MlpPolicy'           # Type of Policy
batch_size: 4096              # Minibatch size
gamma: 0.99                   # Discount factor
ent_coef: 0.01                # Entropy coefficient
learning_starts: 1000         # How many steps of the model to collect transitions for before learning starts
learning_rate: !!float 1e-4
use_sde: True                 # Mandatory if "squash_output" is activated
policy_kwargs: "dict(
                  activation_fn=torch.nn.Tanh,
                  net_arch=[256, 128, 64],
                  share_features_extractor = True,
                )"
device: "cpu"              # Device
# normalize_input: False        # Wether to normalize observations and action